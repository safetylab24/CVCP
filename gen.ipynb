{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from pyquaternion import Quaternion\n",
    "import numpy as np\n",
    "\n",
    "CAMERAS = ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT']\n",
    "\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot='CVCP/nuscenes', verbose=True)\n",
    "\n",
    "# generate pkl for each scene\n",
    "# each pkl will have the following structure:\n",
    "# [{\n",
    "#     \"scene\": \"scene_name\",\n",
    "#     \"token\": sample_token\n",
    "#     \"intrinsics\": [I1, I2, I3, I4, I5, I6, I7, I8, I9],\n",
    "#     \"extrinsics\": [E1, E2, E3, E4, E5, E6, E7, E8, E9, E10, E11, E12, E13, E14, E15, E16],\n",
    "#     \"images\": [image_path1, image_path2, image_path3, image_path4, image_path5, image_path6},\n",
    "# }, ...]\n",
    "\n",
    "def get_transformation_matrix(R, t, inv=False):\n",
    "    pose = np.eye(4, dtype=np.float32)\n",
    "    pose[:3, :3] = R if not inv else R.T\n",
    "    pose[:3, -1] = t if not inv else R.T @ -t\n",
    "\n",
    "    return pose\n",
    "\n",
    "def get_pose(rotation, translation, inv=False, flat=False):\n",
    "    if flat:\n",
    "        yaw = Quaternion(rotation).yaw_pitch_roll[0]\n",
    "        R = Quaternion(scalar=np.cos(yaw / 2), vector=[0, 0, np.sin(yaw / 2)]).rotation_matrix\n",
    "    else:\n",
    "        R = Quaternion(rotation).rotation_matrix\n",
    "\n",
    "    t = np.array(translation, dtype=np.float32)\n",
    "\n",
    "    return get_transformation_matrix(R, t, inv=inv)\n",
    "\n",
    "def parse_pose(record, *args, **kwargs):\n",
    "    return get_pose(record['rotation'], record['translation'], *args, **kwargs)\n",
    "\n",
    "def parse_sample_record(sample_record, camera_rig):\n",
    "        lidar_record = nusc.get('sample_data', sample_record['data']['LIDAR_TOP'])\n",
    "        egolidar = nusc.get('ego_pose', lidar_record['ego_pose_token'])\n",
    "\n",
    "        world_from_egolidarflat = parse_pose(egolidar, flat=True)\n",
    "        egolidarflat_from_world = parse_pose(egolidar, flat=True, inv=True)\n",
    "\n",
    "        cam_channels = []\n",
    "        images = []\n",
    "        intrinsics = []\n",
    "        extrinsics = []\n",
    "\n",
    "        for cam_idx in camera_rig:\n",
    "            cam_channel = CAMERAS[cam_idx]\n",
    "            cam_token = sample_record['data'][cam_channel]\n",
    "\n",
    "            cam_record = nusc.get('sample_data', cam_token)\n",
    "            egocam = nusc.get('ego_pose', cam_record['ego_pose_token'])\n",
    "            cam = nusc.get('calibrated_sensor', cam_record['calibrated_sensor_token'])\n",
    "\n",
    "            cam_from_egocam = parse_pose(cam, inv=True)\n",
    "            egocam_from_world = parse_pose(egocam, inv=True)\n",
    "\n",
    "            E = cam_from_egocam @ egocam_from_world @ world_from_egolidarflat\n",
    "            I = cam['camera_intrinsic']\n",
    "\n",
    "            full_path = Path(nusc.get_sample_data_path(cam_token))\n",
    "            image_path = str(full_path.relative_to(nusc.dataroot))\n",
    "\n",
    "            # cam_channels.append(cam_channel)\n",
    "            intrinsics.append(I)\n",
    "            extrinsics.append(E.tolist())\n",
    "            images.append(image_path)\n",
    "\n",
    "        return {\n",
    "            'scene': '',\n",
    "            'token': sample_record['token'],\n",
    "\n",
    "            'pose': world_from_egolidarflat.tolist(),\n",
    "            'pose_inverse': egolidarflat_from_world.tolist(),\n",
    "\n",
    "            'cam_ids': list(camera_rig),\n",
    "            'cam_channels': cam_channels,\n",
    "            'intrinsics': intrinsics,\n",
    "            'extrinsics': extrinsics,\n",
    "            'images': images,\n",
    "        }\n",
    "\n",
    "def parse_scene(scene_record, camera_rigs=[[0, 1, 2, 3, 4, 5]]):\n",
    "        data = []\n",
    "        sample_token = scene_record['first_sample_token']\n",
    "\n",
    "        while sample_token:\n",
    "            sample_record = nusc.get('sample', sample_token)\n",
    "\n",
    "            for camera_rig in camera_rigs:\n",
    "                data.append(parse_sample_record(sample_record, camera_rig))\n",
    "\n",
    "            sample_token = sample_record['next']\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "for scene in nusc.scene:\n",
    "    data = parse_scene(scene)\n",
    "    with open(f'CVCP/nuscenes/{scene[\"name\"]}.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f'Generated {scene[\"name\"]}.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
